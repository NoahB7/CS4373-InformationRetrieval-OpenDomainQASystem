{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install pytorch and transformers in anaconda prompt beforehand\n",
    "# pip install torch\n",
    "# pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertForQuestionAnswering\n",
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "480948affec244ea926322e36d9cc23f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=443.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d758b43a426a4bcca0b27f72def01666",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=1340675298.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
    "# model and tokenizer only need to be run once to load in the trained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bcfb885c0824db1a8029429868299bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=231508.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02e89abba8a746cba5b7ca615bb74d1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=28.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bb70acf4f1a4c41987250e30b49134f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=466062.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What was the original meaning of the word Norman?\"\n",
    "text_containing_answer = \"The English name 'Normans' comes from the French words Normans/Normanz, plural of Normant, modern French normand, which is itself borrowed from Old Low Franconian Nortmann 'Northman' or directly from Old Norse Norðmaðr, Latinized variously as Nortmannus, Normannus, or Nordmannus (recorded in Medieval Latin, 9th century) to mean 'Norseman, Viking'.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 2054, 2001, 1996, 2434, 3574, 1997, 1996, 2773, 5879, 1029, 102, 1996, 2394, 2171, 1005, 5879, 2015, 1005, 3310, 2013, 1996, 2413, 2616, 5879, 2015, 1013, 5879, 2480, 1010, 13994, 1997, 5879, 2102, 1010, 2715, 2413, 5879, 2094, 1010, 2029, 2003, 2993, 11780, 2013, 2214, 2659, 9341, 11148, 4496, 22942, 2078, 1005, 2167, 2386, 1005, 2030, 3495, 2013, 2214, 15342, 4496, 29668, 2863, 29668, 2099, 1010, 3763, 3550, 17611, 2004, 4496, 22942, 10182, 1010, 5879, 10182, 1010, 2030, 13926, 5804, 2271, 1006, 2680, 1999, 5781, 3763, 1010, 6280, 2301, 1007, 2000, 2812, 1005, 15342, 2386, 1010, 12886, 1005, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "# standard .encode() does not give us segment ID's to define which is answer and question\n",
    "# .encode_plus() will do this for us\n",
    "input_ids = tokenizer.encode_plus(text=question, text_pair=text_containing_answer)\n",
    "# number encodes the word contained in question and text_containing_answer\n",
    "print(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'what', 'was', 'the', 'original', 'meaning', 'of', 'the', 'word', 'norman', '?', '[SEP]', 'the', 'english', 'name', \"'\", 'norman', '##s', \"'\", 'comes', 'from', 'the', 'french', 'words', 'norman', '##s', '/', 'norman', '##z', ',', 'plural', 'of', 'norman', '##t', ',', 'modern', 'french', 'norman', '##d', ',', 'which', 'is', 'itself', 'borrowed', 'from', 'old', 'low', 'franco', '##nian', 'nor', '##tman', '##n', \"'\", 'north', '##man', \"'\", 'or', 'directly', 'from', 'old', 'norse', 'nor', '##ð', '##ma', '##ð', '##r', ',', 'latin', '##ized', 'variously', 'as', 'nor', '##tman', '##nus', ',', 'norman', '##nus', ',', 'or', 'nord', '##mann', '##us', '(', 'recorded', 'in', 'medieval', 'latin', ',', '9th', 'century', ')', 'to', 'mean', \"'\", 'norse', '##man', ',', 'viking', \"'\", '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer.convert_ids_to_tokens(input_ids['input_ids'])\n",
    "# swapping back the ids back to their tokens to make sure it worked\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_scores, end_scores = model(torch.tensor([input_ids['input_ids']]),# ids for tokens\n",
    "                                 token_type_ids=torch.tensor([input_ids['token_type_ids']]),# identification question and answer\n",
    "                                return_dict=False)# it just returns the name of the dict if we dont set this to False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What was the original meaning of the word Norman?\n",
      "Answer: norse ##man , viking\n"
     ]
    }
   ],
   "source": [
    "answer_start = torch.argmax(start_scores) # start of answer that is most probable\n",
    "answer_end = torch.argmax(end_scores) # end of answer\n",
    "\n",
    "# inputing the token ids to get back what the actual un-enconded version of the word is and concatenating it into a string\n",
    "# to create the answer\n",
    "answer = ' '.join(tokens[answer_start:answer_end+1])\n",
    "\n",
    "print('Question: ' + question)\n",
    "\n",
    "print('Answer: ' + answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
